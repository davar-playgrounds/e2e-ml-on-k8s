{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notebook to demonstrate end to end reproducible machine learning on Kubernetes\n",
    "\n",
    "This is divided into two sections: \n",
    "1. Reproducible machine learning workflow with Tensorflow 2: A semantic segmentation problem\n",
    "2. Deployment of 1) on kubernetes with Kubeflow & Pachyderm for full provenance and reproducibility"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 1. Reproducible machine learning workflow with Tensorflow 2: A semantic segmentation problem\n",
    "\n",
    "Machine learning algorithms often required complex computation. This is increasing becoming true as we move towards complex network architectures that requires Giga FLOPs/ Tera FLOPs computations.\n",
    "We move more and more towards GPU and efficient hardware. But the speed and efficiency sometimes comes at a cost of reproducibility. Different GPU architectures due to different stream multiprocessing unit may give different results.\n",
    "Even using parallelism on CPU, may give different results. There is very interesting presentation by Corden [Consistency of Floating Point Results or Why doesn’t my application always give the same answer?”](https://www.nccs.nasa.gov/images/FloatingPoint_consistency.pdf) that covers some of these in details.\n",
    "\t\t\t      \t\n",
    "It is not just hardware, some libraries performing intensive computations do not guarantee reproducibility for some routines. One such example is [NVIDIA's deep neural network library](https://developer.nvidia.com/cudnn) that do not guarantee same bitwise results even on same GPU for some routines [ref](https://docs.nvidia.com/deeplearning/sdk/cudnn-developer-guide/index.html#reproducibility).\n",
    "\n",
    "Then we have randomness! Algorithmic randomness like Dropouts, Random initializations, Random augmentations or more process and practice based randomness such as shuffle of data etc. Using unseeded randomness also make reproducibility very hard.  \n",
    "\n",
    "Using Tensorflow 2.0, 100% reproducible deep learning can be practiced if used correctly. This is due to [Duncan Riach](https://github.com/duncanriach) excellent work [https://github.com/NVIDIA/](https://github.com/NVIDIA/tensorflow-determinism). Also, thanks to wider Tensorflow team.\n",
    "[“Determinism in deep learning” By Duncan Riach @ GTC 2019](https://drive.google.com/file/d/18pmjeiXWqzHWB8mM2mb3kjN4JSOZBV4A/view) is very interesting presentation as well. \n",
    "\n",
    "Other than seeding all randomness in all layers of my ML network, executing set_global_determinism [set_global_determinism](https://github.com/suneeta-mall/e2e-ml-on-k8s/blob/master/pypkg/pylib/utils.py#L15-L42) method guarantees 100% same results if fed with same dataset.\n",
    "\n",
    "```python\n",
    "def set_global_determinism(seed=42, fast_n_close=False):\n",
    "    \"\"\"\n",
    "        Enable 100% reproducibility on operations related to tensor and randomness.\n",
    "        Parameters:\n",
    "        seed (int): seed value for global randomness\n",
    "        fast_n_close (bool): whether to achieve efficient at the cost of determinism/reproducibility\n",
    "    \"\"\"\n",
    "    set_seeds(seed=seed)\n",
    "    if fast_n_close:\n",
    "        return\n",
    "\n",
    "    logging.warning(\"*******************************************************************************\")\n",
    "    logging.warning(\"*** set_global_determinism is called,setting full determinism, will be slow ***\")\n",
    "    logging.warning(\"*******************************************************************************\")\n",
    "\n",
    "    os.environ['TF_DETERMINISTIC_OPS'] = '1'\n",
    "    os.environ['TF_CUDNN_DETERMINISTIC'] = '1'\n",
    "    # https://www.tensorflow.org/api_docs/python/tf/config/threading/set_inter_op_parallelism_threads\n",
    "    tf.config.threading.set_inter_op_parallelism_threads(1)\n",
    "    tf.config.threading.set_intra_op_parallelism_threads(1)\n",
    "    from tfdeterminism import patch\n",
    "    patch()\n",
    "\n",
    "def set_seeds(seed=42):\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    random.seed(seed)\n",
    "    tf.random.set_seed(seed)\n",
    "    np.random.seed(seed)\n",
    "```\n",
    "\n",
    "To run the e2e example locally, run following. This implements machine learning workflow shown below:\n",
    "![Machine learning workflow](resources/ml-workflow.jpg \"Machine learning workflow\")\n",
    "\n",
    "with training code scripted in [train.py](app/train.py). See [ML workflow steps details](ML_WORKFLOWS.md) for more information on other steps."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "! docker run -t -i --rm --name e2e-ml --entrypoint bash suneetamall/e2e-ml-on-k8s:latest /run_e2e.sh"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 2. Deployment of 1) on kubernetes with Kubeflow & Pachyderm for full provenance and reproducibility\n",
    "\n",
    "However, 100% reproducible machine learning code comes at a cost. With this particular, pet segmentation problem, noticeable increase of 3.75 times higher training time is observed. \n",
    "This may not be acceptable if we are only looking at variance in results in order of 0.5 unit (eg range of accuracy 91.0-91.5 on various run). In such scenarios, maintaining full provenance \n",
    "becomes really important. This is not just limited to maintaining the lineage to training data but should be extended to entire workflow including serving of model and infrastructural components.\n",
    "\n",
    "This section caters to that scenario. Follow instructions below for demo:\n",
    "\n",
    "Prerequisite \n",
    "- Install Kubectl suitable to Kube version\n",
    "- Install [pachctl 1.9.8](https://github.com/pachyderm/pachyderm/releases/tag/v1.9.8)\n",
    "- Basically BYO Kubernetes cluster, install ArgoCD ([quick guide](https://github.com/suneeta-mall/e2e-ml-on-k8s/blob/master/cluster-conf/README.md#configuring-kubernetes-cluster-with-gitops)) "
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Install ArgoCD app\n",
    "! kubectl apply –f https://raw.githubusercontent.com/suneeta-mall/e2e-ml-on-k8s/master/cluster-conf/e2e-ml-argocd-app.yaml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Configure pachctl \n",
    "! pachctl config update context `pachctl config get active-context` --namespace kubeflow\n",
    "! pachctl port-forward & "
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Pipeline specification\n",
    "See [ML workflow steps details](ML_WORKFLOWS.md) for detailed introduction on each step of the ML workflow.\n",
    "There are two type ml workflow pipeline spec defined: \n",
    "1. [Pachyderm only pipeline](cluster-conf/k8s/ml-workflow/pachyderm-specs.yaml)\n",
    "2. [Pachyderm in conjunction with Kubeflow](cluster-conf/k8s/ml-workflow/extend_pachyderm-specs-with-kubeflow.yaml)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Pachyderm only pipeline\n",
    "! pygmentize cluster-conf/k8s/ml-workflow/pachyderm-specs.yaml\n",
    "! pachctl create pipeline -f cluster-conf/k8s/ml-workflow/pachyderm-specs.yaml"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Pachyderm in conjunction with Kubeflow\n",
    "! pygmentize cluster-conf/k8s/ml-workflow/extend_pachyderm-specs-with-kubeflow.yaml\n",
    "! pachctl create pipeline -f cluster-conf/k8s/ml-workflow/extend_pachyderm-specs-with-kubeflow.yaml\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Checking for status on processes\n",
    "See [pachctl](https://docs.pachyderm.com/latest/reference/pachctl/pachctl_list_job/) reference to check on job status.\n",
    "An example output may look like following:\n",
    "```\n",
    "ID                               PIPELINE    STARTED      DURATION       RESTART PROGRESS  DL       UL       STATE\n",
    "116788baecd54d0ba15f4dd5372a8f15 model-kf    46 hours ago 50 minutes     0       1 + 0 / 1 43.32MiB 278.7MiB success\n",
    "c7efc83593854f8291af6db577fd286c release     2 days ago   18 seconds     0       1 + 0 / 1 177.7MiB 0B       success\n",
    "8ae9a293f2b94ab5ba2ae02186783025 evaluate    2 days ago   11 minutes     0       1 + 0 / 1 180.7MiB 1.277MiB success\n",
    "046f26e008fe4c009c7f338997aaedb6 tune-kf     2 days ago   4 hours        0       1 + 0 / 1 0B       116B     success\n",
    "2e6dec46669e4360bbf6e2ba3ee6da61 calibrate   2 days ago   5 minutes      0       1 + 0 / 1 143.2MiB 37.4MiB  success\n",
    "b5d2feebc0ef4d15893e27562b11636f tensorboard 2 days ago   -              0       0 + 0 / 0 0B       0B       running\n",
    "9a74b4195b044390a7afb08c0dde63e4 model       2 days ago   8 hours        0       1 + 0 / 1 43.32MiB 1.224GiB success\n",
    "54db4db243b24ec8aa2bbe4d3b8ce8bd train       2 days ago   7 hours        0       1 + 0 / 1 43.32MiB 974.5MiB success\n",
    "f3d0b49316254e968fd996caeb333a14 tune        2 days ago   4 hours        0       1 + 0 / 1 43.32MiB 1.088GiB success\n",
    "016942a72bc34dca882f318fa3779a68 transform   3 days ago   9 minutes      0       1 + 0 / 1 777.7MiB 43.32MiB success\n",
    "7468207b23aa4e5097be5a926d15a0b4 warehouse   3 days ago   About a minute 0       1 + 0 / 1 773.5MiB 777.7MiB success\n",
    "```"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "! pachctl list job\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Checking predictions\n",
    "Once the release step is complete, a Seldon deployment is created which starts prediction server with version of released model."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Enable port-forward if no ingress/loadbalancer is set\n",
    "! kubectl port-forward -n istio-system svc/istio-ingressgateway 8080:80"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import seldon_core\n",
    "from pylib import TUNE_CONF\n",
    "from pylib import load_validation as load_test, dataset_for_split, display, binarize, IMG_CHANNEL, IMG_HEIGHT, IMG_WIDTH\n",
    "from seldon_core.seldon_client import SeldonClient\n",
    "\n",
    "release_commit = input()\n",
    "input_data_dir=\"resources\"\n",
    "prediction_version=f'petset-{release_commit[0:6]}'\n",
    "\n",
    "test_slice = dataset_for_split(input_data_dir, \"calibration\")\n",
    "test_dataset = test_slice.map(load_test, num_parallel_calls=TUNE_CONF).batch(1)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Requesting prediction from versioned API\n",
    "sc = SeldonClient(gateway=\"istio\", transport=\"rest\", deployment_name=prediction_version,namespace='kubeflow', \n",
    "                  gateway_endpoint='localhost:8080')\n",
    "for img, mask in test_dataset.take(1):\n",
    "    # http://localhost:8080/seldon/kubeflow/petset-c517ec/api/v0.1/predictions\n",
    "    # https://docs.seldon.io/projects/seldon-core/en/latest/workflow/serving.html\n",
    "    r = sc.predict(shape=(IMG_HEIGHT, IMG_WIDTH, IMG_CHANNEL), data=img[0].numpy(), payload_type='ndarray', names=[])\n",
    "    predictions = seldon_core.utils.seldon_message_to_json(r.response)\n",
    "    prediction_res = np.asarray(predictions['data']['ndarray'])\n",
    "    display([img[0], mask[0], prediction_res, binarize(prediction_res)], \n",
    "            title=['Input Image', 'True Mask', 'Predicted Mask', 'Thresholded Mask'])\n",
    "    "
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Sending feedback to versioned API (this currently uses reinforcement send_feedback API ignoring reward but custom APIs can be added on serving component for feedback\n",
    "# truth_pred = seldon_core.utils.seldon_message_to_json(r.response)\n",
    "fb_res=sc.feedback(prediction_request=r.request, prediction_response=r.response, reward=None)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "source": [],
    "metadata": {
     "collapsed": false
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}